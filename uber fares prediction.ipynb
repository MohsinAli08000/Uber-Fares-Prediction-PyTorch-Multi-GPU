{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group, get_rank, get_world_size\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from rich.progress import track\n",
    "from math import *\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group, get_rank, get_world_size\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from rich.progress import track\n",
    "from math import *\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            key  fare_amount  \\\n",
       "0    24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1    27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2    44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3    25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4    17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "\n",
       "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C://Users//HP//Documents//uber.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Unnamed: 0         200000 non-null  int64  \n",
      " 1   key                200000 non-null  object \n",
      " 2   fare_amount        200000 non-null  float64\n",
      " 3   pickup_datetime    200000 non-null  object \n",
      " 4   pickup_longitude   200000 non-null  float64\n",
      " 5   pickup_latitude    200000 non-null  float64\n",
      " 6   dropoff_longitude  199999 non-null  float64\n",
      " 7   dropoff_latitude   199999 non-null  float64\n",
      " 8   passenger_count    200000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>199999.000000</td>\n",
       "      <td>199999.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.771250e+07</td>\n",
       "      <td>11.359955</td>\n",
       "      <td>-72.527638</td>\n",
       "      <td>39.935885</td>\n",
       "      <td>-72.525292</td>\n",
       "      <td>39.923890</td>\n",
       "      <td>1.684535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.601382e+07</td>\n",
       "      <td>9.901776</td>\n",
       "      <td>11.437787</td>\n",
       "      <td>7.720539</td>\n",
       "      <td>13.117408</td>\n",
       "      <td>6.794829</td>\n",
       "      <td>1.385997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-1340.648410</td>\n",
       "      <td>-74.015515</td>\n",
       "      <td>-3356.666300</td>\n",
       "      <td>-881.985513</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.382535e+07</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-73.992065</td>\n",
       "      <td>40.734796</td>\n",
       "      <td>-73.991407</td>\n",
       "      <td>40.733823</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.774550e+07</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>-73.981823</td>\n",
       "      <td>40.752592</td>\n",
       "      <td>-73.980093</td>\n",
       "      <td>40.753042</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.155530e+07</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>-73.967154</td>\n",
       "      <td>40.767158</td>\n",
       "      <td>-73.963658</td>\n",
       "      <td>40.768001</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.542357e+07</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>57.418457</td>\n",
       "      <td>1644.421482</td>\n",
       "      <td>1153.572603</td>\n",
       "      <td>872.697628</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0    fare_amount  pickup_longitude  pickup_latitude  \\\n",
       "count  2.000000e+05  200000.000000     200000.000000    200000.000000   \n",
       "mean   2.771250e+07      11.359955        -72.527638        39.935885   \n",
       "std    1.601382e+07       9.901776         11.437787         7.720539   \n",
       "min    1.000000e+00     -52.000000      -1340.648410       -74.015515   \n",
       "25%    1.382535e+07       6.000000        -73.992065        40.734796   \n",
       "50%    2.774550e+07       8.500000        -73.981823        40.752592   \n",
       "75%    4.155530e+07      12.500000        -73.967154        40.767158   \n",
       "max    5.542357e+07     499.000000         57.418457      1644.421482   \n",
       "\n",
       "       dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "count      199999.000000     199999.000000    200000.000000  \n",
       "mean          -72.525292         39.923890         1.684535  \n",
       "std            13.117408          6.794829         1.385997  \n",
       "min         -3356.666300       -881.985513         0.000000  \n",
       "25%           -73.991407         40.733823         1.000000  \n",
       "50%           -73.980093         40.753042         1.000000  \n",
       "75%           -73.963658         40.768001         2.000000  \n",
       "max          1153.572603        872.697628       208.000000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount          pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          7.5  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1          7.7  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2         12.9  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3          5.3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4         16.0  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0','key'], axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 199999 entries, 0 to 199999\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   fare_amount        199999 non-null  float64\n",
      " 1   pickup_datetime    199999 non-null  object \n",
      " 2   pickup_longitude   199999 non-null  float64\n",
      " 3   pickup_latitude    199999 non-null  float64\n",
      " 4   dropoff_longitude  199999 non-null  float64\n",
      " 5   dropoff_latitude   199999 non-null  float64\n",
      " 6   passenger_count    199999 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          7.5 2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1          7.7 2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2         12.9 2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3          5.3 2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4         16.0 2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "df['pickup_datetime']=pd.to_datetime(df['pickup_datetime'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'seaborn'\n",
    "pio.renderers.default\n",
    "\n",
    "def plot_lat_long(lat: np.ndarray, long: np.ndarray):\n",
    "    # Select 10000 random items from the array\n",
    "    random_lat = np.random.choice(lat, size=10000, replace=False)\n",
    "    random_long = np.random.choice(long, size=10000, replace=False)\n",
    "\n",
    "    # Convert the result to a numpy array\n",
    "    random_lat = np.array(random_lat)\n",
    "    random_long = np.array(random_long)\n",
    "\n",
    "    # Calculate the bounding box of your points\n",
    "    min_lat, max_lat = np.min(random_lat), np.max(random_lat)\n",
    "    min_long, max_long = np.min(random_long), np.max(random_long)\n",
    "\n",
    "    # Center the map on the bounding box\n",
    "    center_lat = (min_lat + max_lat) / 2\n",
    "    center_long = (min_long + max_long) / 2\n",
    "    \n",
    "    # Create a scatter plot\n",
    "    fig = go.Figure(data=go.Scattergeo(\n",
    "        lat=random_lat,\n",
    "        lon=random_long,\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color='rgb(255, 0, 0)', symbol='circle', line=dict(width=0.5, color='white'))\n",
    "    ))\n",
    "    \n",
    "    # Set mapbox style\n",
    "    fig.update_layout(\n",
    "        geo=dict(\n",
    "            scope='world',\n",
    "            projection_type='natural earth',\n",
    "            showland=True,\n",
    "            landcolor='lightgray',\n",
    "            showlakes=True,\n",
    "            lakecolor='lightblue',\n",
    "            showocean=True,\n",
    "            oceancolor='lightblue',\n",
    "            # center=dict(lat=center_lat, lon=center_long),\n",
    "        ),\n",
    "        title_text=\"Scatter Plot of Latitude and Longitude\",  # Add a title\n",
    "        title_font=dict(size=20),  # Adjust title font size\n",
    "        width=1100,\n",
    "        height=800,\n",
    "        legend=dict(\n",
    "            title=\"Legend\",  # Add a legend title\n",
    "            x=0.8,  # Adjust legend position\n",
    "            y=0.9  \n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    return fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "# Now call your function\n",
    "plot_lat_long(lat=df['pickup_latitude'], long=df['pickup_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          7.5 2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1          7.7 2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2         12.9 2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3          5.3 2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4         16.0 2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing train/val/test sets\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.683323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.457590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.036377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.661683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4.475450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          7.5 2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1          7.7 2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2         12.9 2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3          5.3 2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4         16.0 2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  hour  day_of_week  \\\n",
       "0         -73.999512         40.723217                1    19            3   \n",
       "1         -73.994710         40.750325                1    20            4   \n",
       "2         -73.962565         40.772647                1    21            0   \n",
       "3         -73.965316         40.803349                3     8            4   \n",
       "4         -73.973082         40.761247                5    17            3   \n",
       "\n",
       "   month  distance_km  is_weekend  is_night  \n",
       "0      5     1.683323           0         0  \n",
       "1      7     2.457590           0         0  \n",
       "2      8     5.036377           0         0  \n",
       "3      6     1.661683           0         0  \n",
       "4      8     4.475450           0         0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "df['day_of_week'] = df['pickup_datetime'].dt.dayofweek\n",
    "df['month'] = df['pickup_datetime'].dt.month\n",
    "\n",
    "# Calculate distance\n",
    "# df['distance'] = np.sqrt(\n",
    "#     (df['dropoff_longitude'] - df['pickup_longitude'])**2 +\n",
    "#     (df['dropoff_latitude'] - df['pickup_latitude'])**2)\n",
    "def distance_transform(longitude1, latitude1, longitude2, latitude2):\n",
    "    Distance = []\n",
    "    \n",
    "    for pos in range(len(longitude1)):\n",
    "        long1,lati1,long2,lati2 = map(radians,[longitude1[pos],latitude1[pos],longitude2[pos],latitude2[pos]])\n",
    "        dist_long = long2 - long1\n",
    "        dist_lati = lati2 - lati1\n",
    "        a = sin(dist_lati/2)**2 + cos(lati1) * cos(lati2) * sin(dist_long/2)**2\n",
    "        c = 2 * asin(sqrt(a))*6371\n",
    "        Distance.append(c)\n",
    "       \n",
    "    return Distance\n",
    "df['distance_km'] = distance_transform(df['pickup_longitude'].to_numpy(),\n",
    "                                                df['pickup_latitude'].to_numpy(),\n",
    "                                                df['dropoff_longitude'].to_numpy(),\n",
    "                                                df['dropoff_latitude'].to_numpy()\n",
    "                                              )\n",
    "\n",
    "# Time-based features\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(is_weekend\n",
       " 0    143307\n",
       " 1     56692\n",
       " Name: count, dtype: int64,\n",
       " is_night\n",
       " 0    153410\n",
       " 1     46589\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_weekend.value_counts(),df.is_night.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 167398 entries, 0 to 199999\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype              \n",
      "---  ------             --------------   -----              \n",
      " 0   fare_amount        167398 non-null  float64            \n",
      " 1   pickup_datetime    167398 non-null  datetime64[ns, UTC]\n",
      " 2   pickup_longitude   167398 non-null  float64            \n",
      " 3   pickup_latitude    167398 non-null  float64            \n",
      " 4   dropoff_longitude  167398 non-null  float64            \n",
      " 5   dropoff_latitude   167398 non-null  float64            \n",
      " 6   passenger_count    167398 non-null  int64              \n",
      " 7   hour               167398 non-null  int32              \n",
      " 8   day_of_week        167398 non-null  int32              \n",
      " 9   month              167398 non-null  int32              \n",
      " 10  distance_km        167398 non-null  float64            \n",
      " 11  is_weekend         167398 non-null  int64              \n",
      " 12  is_night           167398 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(6), int32(3), int64(3)\n",
      "memory usage: 16.0 MB\n"
     ]
    }
   ],
   "source": [
    "locations=['pickup_latitude','pickup_longitude','dropoff_longitude','dropoff_latitude','fare_amount','distance_km']\n",
    "for i in locations:\n",
    "    lower_limit=df[i].quantile(0.02)\n",
    "    upper_limit=df[i].quantile(0.99)\n",
    "    df=df[(df[i]>=lower_limit) & (df[i]<=upper_limit)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 167398 entries, 0 to 199999\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   passenger_count  167398 non-null  float32\n",
      " 1   hour             167398 non-null  float32\n",
      " 2   day_of_week      167398 non-null  float32\n",
      " 3   month            167398 non-null  float32\n",
      " 4   distance_km      167398 non-null  float32\n",
      " 5   is_weekend       167398 non-null  float32\n",
      " 6   is_night         167398 non-null  float32\n",
      " 7   fare_amount      167398 non-null  float32\n",
      "dtypes: float32(8)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "# df['pickup_datetime'] = df['pickup_datetime'].astype('float64')\n",
    "# df['passenger_count'] = df['passenger_count'].astype('float64')\n",
    "df = df[['passenger_count', 'hour', 'day_of_week', 'month', 'distance_km', 'is_weekend', 'is_night', 'fare_amount']].astype('float32')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_night</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.683323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.457590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.036377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.661683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.475450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  hour  day_of_week  month  distance_km  is_weekend  \\\n",
       "0              1.0  19.0          3.0    5.0     1.683323         0.0   \n",
       "1              1.0  20.0          4.0    7.0     2.457590         0.0   \n",
       "2              1.0  21.0          0.0    8.0     5.036377         0.0   \n",
       "3              3.0   8.0          4.0    6.0     1.661683         0.0   \n",
       "4              5.0  17.0          3.0    8.0     4.475450         0.0   \n",
       "\n",
       "   is_night  fare_amount  \n",
       "0       0.0          7.5  \n",
       "1       0.0          7.7  \n",
       "2       0.0         12.9  \n",
       "3       0.0          5.3  \n",
       "4       0.0         16.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('fare_amount', axis=1)\n",
    "y = df['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_tst, y_val, y_tst = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((117178, 7), (117178,), (25110, 7), (25110,), (25110, 7), (25110,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_tst.shape, y_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xt_scaled = scaler.fit_transform(X_train)\n",
    "Xv_scaled = scaler.transform(X_val)\n",
    "Xts_scaled = scaler.transform(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39.83000183105469, 3.5)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y),min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_scaled_t = torch.from_numpy(Xt_scaled)\n",
    "Xv_scaled_t = torch.from_numpy(Xv_scaled)\n",
    "Xts_scaled_t = torch.from_numpy(Xts_scaled)\n",
    "\n",
    "yt_tensor = torch.from_numpy(y_train.to_numpy())\n",
    "yv_tensor = torch.from_numpy(y_val.to_numpy())\n",
    "yts_tensor = torch.from_numpy(y_tst.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Xt_scaled_t, 'X_train.pt')\n",
    "torch.save(yt_tensor, 'y_train.pt')\n",
    "torch.save(Xv_scaled_t, 'X_val.pt')\n",
    "torch.save(yv_tensor, 'y_val.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_true: np.ndarray , y_pred: np.ndarray, delta: float=1.0):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = np.abs(error) <= delta\n",
    "    squared_loss = np.square(error) / 2\n",
    "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
    "    return np.mean(np.where(is_small_error, squared_loss, linear_loss))\n",
    "\n",
    "huber_scorer = make_scorer(huber_loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val score: 0.7450\n",
      "val MAE: 1.8227\n",
      "val Huber Loss: 1.3941\n",
      "test score: 0.7296\n",
      "test MAE: 1.8370\n",
      "test Huber Loss: 1.4086\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(Xt_scaled, y_train)\n",
    "print(f\"val score: {linear_model.score(Xv_scaled, y_val):.4f}\")\n",
    "lyv_preds = linear_model.predict(Xv_scaled)\n",
    "print(f\"val MAE: {mean_absolute_error(np.array(y_val), lyv_preds):.4f}\")\n",
    "print(f\"val Huber Loss: {huber_loss(np.array(y_val), lyv_preds):.4f}\")\n",
    "print(f\"test score: {linear_model.score(Xts_scaled, y_tst):.4f}\")\n",
    "lyts_preds = linear_model.predict(Xts_scaled)\n",
    "print(f\"test MAE: {mean_absolute_error(np.array(y_tst), lyts_preds):.4f}\")\n",
    "print(f\"test Huber Loss: {huber_loss(np.array(y_tst), lyts_preds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val score: 0.5023\n",
      "val MAE: 2.5217\n",
      "val Huber Loss: 2.0863\n",
      "test score: 0.4792\n",
      "test MAE: 2.5528\n",
      "test Huber Loss: 2.1156\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeRegressor()\n",
    "tree_model.fit(Xt_scaled, y_train)\n",
    "print(f\"val score: {tree_model.score(Xv_scaled, y_val):.4f}\")\n",
    "lyv_preds = tree_model.predict(Xv_scaled)\n",
    "print(f\"val MAE: {mean_absolute_error(np.array(y_val), lyv_preds):.4f}\")\n",
    "print(f\"val Huber Loss: {huber_loss(np.array(y_val), lyv_preds):.4f}\")\n",
    "print(f\"test score: {tree_model.score(Xts_scaled, y_tst):.4f}\")\n",
    "lyts_preds = tree_model.predict(Xts_scaled)  \n",
    "print(f\"test MAE: {mean_absolute_error(np.array(y_tst), lyts_preds):.4f}\")\n",
    "print(f\"test Huber Loss: {huber_loss(np.array(y_tst), lyts_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing torchtrain.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile torchtrain.py\n",
    "\n",
    "import os\n",
    "# os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group, get_rank, get_world_size\n",
    "from rich.progress import track\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "\n",
    "def ddp_setup(rank, world_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        rank: Unique identifier of each process\n",
    "        world_size: Total number of processes\n",
    "    \"\"\"\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_data: torch.utils.data.DataLoader,\n",
    "        val_data: torch.utils.data.DataLoader,\n",
    "        criterion,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        patience: int,\n",
    "        gpu_id: int,\n",
    "#         save_every: int,\n",
    "        save_path: str,\n",
    "        max_epochs: int,\n",
    "        world_size: int,\n",
    "        scheduler = None,\n",
    "    ) -> None:\n",
    "        self.gpu_id = gpu_id\n",
    "#         self.model = model.to(gpu_id)\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.patience = patience\n",
    "        self.save_path = save_path\n",
    "#         self.best_val_loss = float('inf')\n",
    "        self.model = DDP(model.to(gpu_id), device_ids=[gpu_id])\n",
    "        self.train_losses = np.array([{f'train_losses{i}': np.array([]) for i in range(world_size)}])\n",
    "        self.val_losses = np.array([{f'val_losses{i}': np.array([]) for i in range(world_size)}])\n",
    "\n",
    "    def _run_batch(self, source, targets):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(source)\n",
    "#         print(f\"Output shape: {output.shape}, Targets shape: {targets.shape}\")\n",
    "#         loss_fnc = nn.L1Loss().to(self.gpu_id)\n",
    "#         loss = F.l1_loss(output, targets.unsqueeze(1))\n",
    "        loss = self.criterion(output, targets.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=self.model.parameters(), max_norm=1.0, norm_type=2.0)\n",
    "        self.optimizer.step()\n",
    "#         self.scheduler.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def _run_eval(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        self.val_data.sampler.set_epoch(epoch)\n",
    "        with torch.inference_mode():\n",
    "            for source, targets in track(self.val_data, description=f\"Evaluating...\", style='red', complete_style='cyan', finished_style='green'):\n",
    "                source = source.to(self.gpu_id)\n",
    "                targets = targets.to(self.gpu_id)\n",
    "                output = self.model(source)\n",
    "#                 print(f\"Output shape: {output.shape}, Targets shape: {targets.shape}\")\n",
    "#                 loss_fnc = nn.L1Loss().to(self.gpu_id)\n",
    "#                 loss = F.l1_loss(output, targets.unsqueeze(1))\n",
    "                loss = self.criterion(output, targets.unsqueeze(1))\n",
    "                total_loss += loss.item()\n",
    "#         print(f\"val data len: {len(self.val_data)}\")\n",
    "        self.model.train()\n",
    "        return total_loss / len(self.val_data)\n",
    "\n",
    "    def _run_epoch(self, epoch, total_epochs):\n",
    "        b_sz = self.train_data.batch_size\n",
    "        total_loss = 0\n",
    "        self.train_data.sampler.set_epoch(epoch)\n",
    "        for source, targets in track(self.train_data, description=f\"[GPU{self.gpu_id}] Epoch {epoch+1}/{total_epochs} | Training: {b_sz}...\", style='red', complete_style='cyan', finished_style='green'):\n",
    "            source = source.to(self.gpu_id)\n",
    "            targets = targets.to(self.gpu_id)\n",
    "            loss = self._run_batch(source, targets)\n",
    "#             self.scheduler.step(val_loss)\n",
    "            total_loss += loss\n",
    "#         print(f\"train data len: {len(self.train_data)}\")\n",
    "        return total_loss / len(self.train_data)\n",
    "\n",
    "    def _save_checkpoint(self, epoch):\n",
    "        ckp = self.model.module.state_dict()\n",
    "        PATH = f\"{self.save_path}/best_model.pt\"\n",
    "#         if self.gpu_id == 0:\n",
    "        torch.save(ckp, PATH)\n",
    "        print(f\"\\t\\tNew best model saved at {PATH} from GPU{self.gpu_id}.\")\n",
    "            \n",
    "    def loss_metric_tensors(self, array: np.ndarray):\n",
    "        all_tensors = [torch.tensor([[array[0][j][k] for k in range(len(array[0][j]))]], dtype=torch.float32) for j in array[0].keys()]\n",
    "        b = torch.cat(all_tensors, dim=0)\n",
    "        return b.transpose(0, 1)\n",
    "    \n",
    "    def gather_tensor(self, t):\n",
    "        gathered_t = [torch.zeros_like(t) for _ in range(get_world_size())]\n",
    "        torch.distributed.all_gather(gathered_t, t)\n",
    "        return torch.cat(gathered_t, dim=0)\n",
    "\n",
    "    def train(self, max_epochs: int):\n",
    "        b_sz = self.train_data.batch_size  # b_sz = len(next(iter(self.train_data))[0])\n",
    "        should_stop = torch.zeros(1).to(self.gpu_id)\n",
    "        patience_count = torch.zeros(1, dtype=torch.int32).to(self.gpu_id)\n",
    "        for epoch in range(max_epochs):\n",
    "            train_loss = self._run_epoch(epoch, max_epochs)\n",
    "            val_loss = self._run_eval(epoch)\n",
    "            print(f\"\\t[GPU{self.gpu_id}]  Batch: {b_sz} | Train Step: {len(self.train_data)} | Val Step: {len(self.val_data)} | Loss: {train_loss:.4f} | Val_Loss: {val_loss:.4f} | Learning Rate: {self.optimizer.param_groups[0]['lr']:.6f}\")\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Gather losses from all GPUs\n",
    "            world_size = get_world_size()\n",
    "            train_losses = [torch.zeros(1).to(self.gpu_id) for _ in range(world_size)]\n",
    "            val_losses = [torch.zeros(1).to(self.gpu_id) for _ in range(world_size)]\n",
    "            torch.distributed.all_gather(train_losses, torch.tensor([train_loss]).to(self.gpu_id))\n",
    "            torch.distributed.all_gather(val_losses, torch.tensor([val_loss]).to(self.gpu_id))\n",
    "            \n",
    "            # Save losses for all GPUs\n",
    "            for i in range(world_size):\n",
    "                self.train_losses[0][f\"train_losses{i}\"] = np.append(self.train_losses[0][f\"train_losses{i}\"], train_losses[i].item())\n",
    "                self.val_losses[0][f\"val_losses{i}\"] = np.append(self.val_losses[0][f\"val_losses{i}\"], val_losses[i].item())\n",
    "\n",
    "            val_losses_t = self.loss_metric_tensors(self.val_losses)\n",
    "            \n",
    "            vl_last_item = np.min(val_losses_t[-1:].squeeze().numpy())\n",
    "            bval_loss = np.min(val_losses_t.numpy())\n",
    "                \n",
    "            # Find the best validation loss across all GPUs\n",
    "#             best_val_loss = min(val_losses).item()\n",
    "#             if best_val_loss < self.best_val_loss:\n",
    "#                 self.best_val_loss = best_val_loss\n",
    "# #                 if self.gpu_id == 0:  # Only save on the first GPU\n",
    "#                 self._save_checkpoint(epoch)\n",
    "            \n",
    "            improved = torch.tensor([False], dtype=torch.bool).to(self.gpu_id)\n",
    "            if (len(torch.where(val_losses_t==vl_last_item)[1]) == 1):\n",
    "                vl_last_gpu = torch.where(val_losses_t==vl_last_item)[1].item()\n",
    "                if (vl_last_item == bval_loss) and (self.gpu_id == vl_last_gpu):\n",
    "                    print(f\"\\t\\t1:[GPU{self.gpu_id}] val_loss improved to {vl_last_item:.4f}\")\n",
    "                    self._save_checkpoint(epoch)\n",
    "                    improved = torch.tensor([True], dtype=torch.bool).to(self.gpu_id)\n",
    "                    time.sleep(2)\n",
    "            elif (len(torch.where(val_losses_t==vl_last_item)[1]) > 1):\n",
    "                if (vm_last_item == bval_metric):\n",
    "                    vl_last_gpu_min = min(torch.where(val_losses_t==vl_last_item)[1]).item()\n",
    "                    if (self.gpu_id == vl_last_gpu_min):\n",
    "                        print(f\"\\t\\t2:[GPU{self.gpu_id}] val_loss: {vm_last_item:.4f}\")\n",
    "                        self._save_checkpoint(epoch)\n",
    "                        improved = torch.tensor([True], dtype=torch.bool).to(self.gpu_id)\n",
    "                        time.sleep(2)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "            # Synchronize patience count across all GPUs\n",
    "            improved_state = self.gather_tensor(improved)\n",
    "        \n",
    "            # Update patience count\n",
    "            if (improved_state[0] and improved_state[1]) or (improved_state[0] or improved_state[1]):\n",
    "                patience_count.zero_()\n",
    "#                 print(f\"\\n[GPU{self.gpu_id}] count zero --> {patience_count}\")\n",
    "            else:\n",
    "                patience_count += 1\n",
    "#                 print(f\"\\n[GPU{self.gpu_id}] count increase --> {patience_count}\")\n",
    "\n",
    "            # Synchronize patience count across all GPUs\n",
    "            all_patience_counts = self.gather_tensor(patience_count)\n",
    "            max_patience_count = torch.max(all_patience_counts).item()\n",
    "            patience_count.fill_(max_patience_count)\n",
    "\n",
    "#             print(f\"\\n[GPU{self.gpu_id}] Patience Count --> {patience_count}\")\n",
    "            \n",
    "            if max_patience_count >= self.patience:\n",
    "                print(f\"\\n[GPU{self.gpu_id}] Patience exceeded. Early stopping...\")\n",
    "#                 break\n",
    "                should_stop[0] = 1\n",
    "    \n",
    "            # Synchronize the should_stop tensor across all GPUs\n",
    "            should_stop_list = [torch.zeros(1).to(self.gpu_id) for _ in range(world_size)]\n",
    "            torch.distributed.all_gather(should_stop_list, should_stop)\n",
    "\n",
    "            # If any GPU wants to stop, all GPUs should stop\n",
    "            if any(stop.item() for stop in should_stop_list):\n",
    "                break\n",
    "        \n",
    "            time.sleep(2)\n",
    "        \n",
    "        # Ensure all GPUs exit the training loop together\n",
    "        torch.distributed.barrier()\n",
    "        \n",
    "        if self.gpu_id == 0:\n",
    "#             print(f\"Training completed.\")\n",
    "            \n",
    "            self.train_losses[0]['epochs'], self.val_losses[0]['epochs'] = np.arange(1, len(self.train_losses[0]['train_losses0'])+1), np.arange(1, len(self.val_losses[0]['val_losses0'])+1)\n",
    "            \n",
    "            np.save(\"train_losses.npy\", self.train_losses, allow_pickle=True)\n",
    "            np.save(\"val_losses.npy\", self.val_losses, allow_pickle=True)\n",
    "\n",
    "\n",
    "# Custom learning rate scheduler\n",
    "class CyclicLRScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, base_lr, max_lr, step_size_up=2000, step_size_down=None, mode='triangular', gamma=1., scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1):\n",
    "        if not isinstance(optimizer, torch.optim.Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "        self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "        self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "        self.step_size_up = step_size_up\n",
    "        self.step_size_down = step_size_down if step_size_down is not None else step_size_up\n",
    "        self.total_size = step_size_up + self.step_size_down\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        self.scale_fn = scale_fn\n",
    "        self.scale_mode = scale_mode\n",
    "        self.cycle_momentum = cycle_momentum\n",
    "        self.base_momentums = [base_momentum] * len(optimizer.param_groups)\n",
    "        self.max_momentums = [max_momentum] * len(optimizer.param_groups)\n",
    "        super(CyclicLRScheduler, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        cycle = np.floor(1 + self.last_epoch / self.total_size)\n",
    "        x = 1 + self.last_epoch / self.total_size - cycle\n",
    "        if x <= 0.5:\n",
    "            scale_factor = x * 2\n",
    "        else:\n",
    "            scale_factor = (1 - x) * 2\n",
    "\n",
    "        lrs = []\n",
    "        for base_lr, max_lr in zip(self.base_lrs, self.max_lrs):\n",
    "            base_height = (max_lr - base_lr) * scale_factor\n",
    "            lr = base_lr + base_height\n",
    "            lrs.append(lr)\n",
    "\n",
    "        return lrs\n",
    "\n",
    "            \n",
    "class CreateDataset_(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "                \n",
    "                \n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.bn3(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "          \n",
    "    \n",
    "def load_data_objs(batch_size: int, rank: int, world_size: int, epochs: int):\n",
    "    Xtrain = torch.load('X_train.pt')\n",
    "    ytrain = torch.load('y_train.pt')\n",
    "    Xval = torch.load('X_val.pt')\n",
    "    yval = torch.load('y_val.pt')\n",
    "    train_dts = CreateDataset_(Xtrain, ytrain)\n",
    "    val_dts = CreateDataset_(Xval, yval)\n",
    "    train_dtl = torch.utils.data.DataLoader(train_dts, batch_size=batch_size, shuffle=False, pin_memory=True, sampler=DistributedSampler(train_dts, num_replicas=world_size, rank=rank))\n",
    "    val_dtl = torch.utils.data.DataLoader(val_dts, batch_size=1, shuffle=False, pin_memory=True, sampler=DistributedSampler(val_dts, num_replicas=world_size, rank=rank))\n",
    "    model = LinearRegressionModel(len(Xtrain[0]))\n",
    "#     criterion = nn.L1Loss()\n",
    "    criterion = nn.HuberLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "#     scheduler = CyclicLRScheduler(optimizer, base_lr=0.0001, max_lr=0.01, step_size_up=2000, mode='min')\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)  # requires metric to step\n",
    "#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, epochs=epochs, steps_per_epoch=len(train_dtl), anneal_strategy='linear')\n",
    "\n",
    "    return train_dtl, val_dtl, model, criterion, optimizer, scheduler\n",
    "\n",
    "def model_eval(model: nn.Module):\n",
    "    print(f\"\\n\\n{'>'*10}LinearRegression Model Evaluation{'<'*10}\\n\")\n",
    "    model.load_state_dict(torch.load(\"best_model/best_model.pt\"))\n",
    "    X_val = torch.load('X_val.pt')\n",
    "    y_val = torch.load('y_val.pt')\n",
    "    val_dts = CreateDataset_(X_val, y_val)\n",
    "    val_dtl = torch.utils.data.DataLoader(val_dts, batch_size=1, shuffle=False, pin_memory=True,)\n",
    "    total_loss = 0\n",
    "    loss_func = nn.L1Loss()\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for source, target in track(val_dtl, description=f\"Evaluating...\", style='red', complete_style='cyan', finished_style='green'):\n",
    "            output = model(source)\n",
    "            loss = loss_func(output, target.unsqueeze(1))\n",
    "            total_loss += loss\n",
    "        print(f\"\\nLoss --> {(total_loss / len(val_dtl)):.4f}\")\n",
    "\n",
    "def main(rank: int, world_size: int, total_epochs: int, patience: int, batch_size: int, save_path: str):\n",
    "    if rank == 0:\n",
    "        print(f\"{'>'*10}LinearRegression Model Training{'<'*10}\\n\")\n",
    "    ddp_setup(rank, world_size)\n",
    "    train_dtl, val_dtl, model, criterion, optimizer, scheduler = load_data_objs(batch_size, rank, world_size, total_epochs)\n",
    "    trainer = Trainer(model, train_dtl, val_dtl, criterion, optimizer, patience, rank, save_path, total_epochs, world_size, scheduler)\n",
    "    trainer.train(total_epochs)\n",
    "    destroy_process_group()\n",
    "    if rank == 0:\n",
    "        print(f\"\\n<{'='*10}Training completed & best model saved{'='*10}>\\nExiting...\")\n",
    "        model_eval(model.to('cpu'))\n",
    "        print(f\"\\n<{'='*10}Evaluation completed{'='*10}>\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    parser = argparse.ArgumentParser(description='simple distributed training job')\n",
    "    parser.add_argument('--total_epochs', default=10, type=int, help='Total epochs to train the model (default: 10)')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Patience for increasing val_loss (default: 5)')\n",
    "    parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')\n",
    "    parser.add_argument('--save_path', default='./checkpoints', type=str, help='Path to save the best model (default: ./checkpoints)')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    world_size = torch.cuda.device_count()\n",
    "    MODEL_PATH = Path(args.save_path)\n",
    "    MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    mp.spawn(main, args=(world_size, args.total_epochs, args.patience, args.batch_size, MODEL_PATH), nprocs=world_size)\n",
    "    end_time = time.time()\n",
    "    print(f'\\nTime Elapsed {(end_time - start_time):.2f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Elapsed 0.01 sec\n"
     ]
    }
   ],
   "source": [
    "!python torchtrain.py --total_epochs 25 --save_path ./best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.exists('data/train_losses.npy')  # Returns True if file exists, False otherwise\n",
    "tl_data = pd.DataFrame(data=np.load(r'C:\\Users\\HP\\Documents\\train_losses.npy', allow_pickle=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_data = pd.DataFrame(data=np.load('C:/Users/HP/Documents/train_losses.npy', allow_pickle=True)[0])\n",
    "vl_data = pd.DataFrame(data=np.load('C:/Users/HP/Documents/val_losses.npy', allow_pickle=True)[0])\n",
    "\n",
    "plot_data = pd.concat([tl_data.drop('epochs', axis=1), vl_data], axis=1)\n",
    "fig1 = px.line(data_frame=plot_data, x='epochs', y=['train_losses0', 'val_losses0'], height=500, title='Train Losses')\n",
    "fig1.update_xaxes(title_text='Epochs',)\n",
    "fig1.update_yaxes(title_text='Losses')\n",
    "fig2 = px.line(data_frame=plot_data, x='epochs', y=['train_losses1', 'val_losses1'], height=500, title='Val Losses')\n",
    "fig2.update_xaxes(title_text='Epochs',)\n",
    "fig2.update_yaxes(title_text='Losses')\n",
    "fig1.show(), fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.leaky_relu(self.bn3(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_dts = MyDataset(Xts_scaled_t, yts_tensor)\n",
    "tst_dtl = torch.utils.data.DataLoader(tst_dts, batch_size=1, shuffle=False, pin_memory=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LinearRegression(len(Xts_scaled_t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>Test Set Evaluation<<<<<\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362de73c143e412da13c1c33b95021df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\">>>>>Test Set Evaluation<<<<<\")\n",
    "total_loss = 0\n",
    "final_model.eval()\n",
    "with torch.inference_mode():\n",
    "    for source, target in track(tst_dtl, description=f\"Evaluating...\", style='red', complete_style='cyan', finished_style='green'):\n",
    "        output = final_model(source)\n",
    "#         loss_func = nn.L1Loss()\n",
    "        loss_func = nn.HuberLoss()\n",
    "        loss = loss_func(output, target.unsqueeze(1))\n",
    "        total_loss += loss\n",
    "    print(f\"\\tLoss --> {total_loss / len(tst_dtl):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparision\n",
    "Linear model Val MAE --> 1.8227 | Val Huber Loss --> 1.3941\n",
    "\n",
    "Linear model Test MAE --> 1.8370 | Test Huber Loss --> 1.4086\n",
    "\n",
    "Dtree model Val MAE --> 2.5368 | Val Huber Loss --> 2.1008\n",
    "\n",
    "Dtree model Test MAE --> 2.5565 | Test Huber Loss --> 2.1196\n",
    "\n",
    "Pytorch model Val L1Loss --> 1.8933 | Val Huber Loss --> 1.8039\n",
    "\n",
    "Pytorch model Test L1Loss --> 1.8935 | Test Huber Loss --> 1.3941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf best_model/best_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
